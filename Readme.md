<div align="center">
<h1 style="font-weight: bold;">Product Data Scraper üöÄ</h1>

![Python](https://img.shields.io/badge/Python-3.10-blue?style=for-the-badge&logo=python)
![Selenium](https://img.shields.io/badge/Selenium-4.27.1-green?style=for-the-badge&logo=selenium)
![Pandas](https://img.shields.io/badge/Pandas-v2.2.3-yellow?style=for-the-badge&logo=pandas)
![psutil](https://img.shields.io/badge/Psutil-v6.1.1-orange?style=for-the-badge&logo=python)
![OpenPyXL](https://img.shields.io/badge/OpenPyXL-3.1.5-purple?style=for-the-badge&logo=python)

</div>

<p align="center">

  ‚Ä¢ [Introdu√ß√£o](#introdu√ß√£o) ‚Ä¢ [Descri√ß√£o](#descri√ß√£o) ‚Ä¢ [Funcionalidades](#funcionalidades) ‚Ä¢ [Estrutura do Projeto](#estrutura-do-projeto) ‚Ä¢ [Depend√™ncias](#depend√™ncias) ‚Ä¢ [Instala√ß√£o](#instala√ß√£o) ‚Ä¢ [Como Usar](#como-usar) ‚Ä¢ [Limpeza e Formata√ß√£o de Dados (Em Desenvolvimento)](#Limpeza-e-Formata√ß√£o) ‚Ä¢ [Sobre o Autor](#sobre-o-autor) ‚Ä¢ [Licen√ßa](#licen√ßa)

</p>

## Introdu√ß√£o

O **Product Data Scraper** √© um conjunto de scripts em Python que automatiza a coleta de dados de produtos a partir de um site. Ele opera em duas etapas principais: 

1. **Captura de Categorias**: Um script inicial coleta os links das categorias de produtos dispon√≠veis no site e salva-os em um arquivo Excel.
2. **Extra√ß√£o de Dados de Produtos**: O segundo script utiliza os links capturados para acessar e extrair informa√ß√µes detalhadas sobre os produtos.

Essa abordagem modular facilita a automa√ß√£o em grande escala e permite um controle mais eficiente do fluxo de dados.

![Captura dos produtos de uma categoria](<images/funcionamento.gif>)


## Descri√ß√£o

Na primeira etapa, o script de captura de categorias utiliza o Selenium para navegar em um site espec√≠fico e identificar os links das categorias. Esses links s√£o salvos em um arquivo Excel, que serve como ponto de partida para o pr√≥ximo script de scraping.

Na segunda etapa, outro script consome os links das categorias e realiza o scraping detalhado dos produtos, incluindo informa√ß√µes como nome, c√≥digo, pre√ßo e impostos.

Voc√™ pode executar e depurar o c√≥digo utilizando Jupyter Notebook ou diretamente no Python.

### Tecnologias Utilizadas

- **Python 3.10**
- **Selenium WebDriver** para automa√ß√£o de navega√ß√£o.
- **Pandas** para manipula√ß√£o de dados e gera√ß√£o de arquivos Excel.
- **Psutil** para monitoramento de uso de mem√≥ria.
- **IPython** para intera√ß√£o avan√ßada e debug.

## Funcionalidades

### Etapa 1: Captura de Categorias
- **Navega√ß√£o Automatizada**:
  - Acessa o site especificado e identifica as categorias de produtos dispon√≠veis.
- **Exporta√ß√£o Estruturada**:
  - Salva os links das categorias em um arquivo Excel para uso posterior.

### Etapa 2: Extra√ß√£o de Dados de Produtos
- **Navega√ß√£o Automatizada**:
  - Acessa links de categorias fornecidos via arquivo Excel.
  - Expande automaticamente listas de produtos nas p√°ginas.
- **Coleta de Dados**:
  - Nome do produto, c√≥digo, pre√ßo, impostos e links individuais.
  - Suporte a m√∫ltiplas categorias.
- **Salvamento Estruturado**:
  - Exporta os dados coletados para arquivos Excel separados por categoria.
- **Gerenciamento de Recursos**:
  - Monitora o uso de mem√≥ria RAM e reinicia o WebDriver quando necess√°rio.

### Sobre o kit_function

O `kit_function` √© um conjunto de fun√ß√µes utilit√°rias desenvolvidas para facilitar a automa√ß√£o de tarefas com o Selenium e manipula√ß√£o de arquivos. Ele inclui fun√ß√µes para aguardar a presen√ßa de elementos em uma p√°gina web, ler e processar arquivos Excel e TXT, al√©m de facilitar a manipula√ß√£o de dados e intera√ß√µes com o navegador.

#### Fun√ß√µes do kit:

- `wait(timeClock)`: Aguarda um tempo espec√≠fico em segundos antes de continuar a execu√ß√£o do script.
- `VerifyElement(by_type, identifier, driver)`: Verifica se um elemento existe na p√°gina, aguardando at√© que ele seja encontrado.
- `readExcel(pathExcel, arrColumns)`: L√™ um arquivo Excel e retorna um DataFrame contendo apenas as colunas especificadas.
- `readTXT(pathfile, array)`: L√™ um arquivo de texto linha por linha e adiciona cada linha a uma lista.
- `append_dict(titles, content, dictionary)`: Adiciona t√≠tulos e valores a um dicion√°rio de dados, garantindo que dados nulos sejam tratados.
- `rollpage(driver, by_type, identifier, step)`: Rola a p√°gina de um site para baixo ou para cima, em uma quantidade espec√≠fica de pixels, facilitando a navega√ß√£o em p√°ginas longas.
- `safe_find_element(driver, by, identifier, default_value=None)`: Tenta localizar um elemento na p√°gina, retornando um valor padr√£o caso o elemento n√£o seja encontrado.
- `newWindow()`: Cria uma nova inst√¢ncia do navegador Edge para ser usada no processo de scraping.

## Estrutura do Projeto

```plaintext
src/
‚îú‚îÄ‚îÄ CapturaDosProdutos.py   # Script que captura os detalhes dos produtos
‚îú‚îÄ‚îÄ CapturaDasCategorias.py   # Script que captura as categorias
‚îú‚îÄ‚îÄ ToolBox/
‚îÇ   ‚îú‚îÄ‚îÄ kit_function.py     # Fun√ß√µes auxiliares para manipula√ß√£o de elementos e dados
‚îÇ   ‚îú‚îÄ‚îÄ login.py            # Automa√ß√£o de login no site
‚îÇ   ‚îî‚îÄ‚îÄ boxString.py        # Credenciais e strings sens√≠veis
‚îú‚îÄ‚îÄ Dados/                  # Diret√≥rio de sa√≠da para arquivos Excel gerados
‚îî‚îÄ‚îÄ Links/
    ‚îî‚îÄ‚îÄ CategoriasMTX.xlsx  # Arquivo com links das categorias
```

## Depend√™ncias
As bibliotecas principais utilizadas no projeto s√£o:

- Selenium: 4.27.1
- Pandas: 2.2.3
- Psutil: 6.1.1
- IPython: 8.31.0
- Openpyxl 3.1.5

## Como Usar

### Etapa 1: Captura de Categorias

1. Execute o script:
```bash
python CapturaDasCategorias.ipynb
```

2. Ap√≥s a execu√ß√£o, o arquivo `CategoriasMTX.xlsx` ser√° salvo no diret√≥rio `Links/`, contendo os links das categorias dispon√≠veis.

```markdown
| Link                               |
|------------------------------------|
| https://example.com/categoria/001  |
| https://example.com/categoria/002  |
```

### Etapa 2: Extra√ß√£o de Dados de Produtos

1. Configure o arquivo `CategoriasMTX.xlsx` no diret√≥rio `Links/` com os links das categorias que deseja capturar.

2. Execute o script principal:
```bash
python CapturaDosProdutos.py
```

3. O script abrir√° um navegador automatizado para acessar os links e capturar os dados.

4. Os resultados ser√£o salvos em arquivos Excel no diret√≥rio `Dados/`.

## Limpeza e Formata√ß√£o
### Desenvolvimento

A parte de limpeza e formata√ß√£o de dados do projeto est√° em andamento. O c√≥digo realiza a limpeza de informa√ß√µes extra√≠das, aplicando express√µes regulares para identificar e extrair dados espec√≠ficos, como c√≥digos de produtos, pre√ßos e tributa√ß√µes (IPI e ST).

### O que est√° em desenvolvimento:

- `Extra√ß√£o de Dados`: Utiliza express√µes regulares para identificar padr√µes como c√≥digos num√©ricos e valores monet√°rios (R$).
- `Formata√ß√£o de Pre√ßos e Impostos`: Est√° sendo implementado um processo para formatar corretamente os pre√ßos, valores de IPI e ST.

## Sobre o Autor

*Este projeto foi desenvolvido por **Kelven Vilela Serejo**, utilizando Python e Selenium para automa√ß√£o e scraping de dados. O objetivo principal √© simplificar e otimizar a captura de informa√ß√µes de produtos em cat√°logos online.*

## Aviso

*Este projeto foi desenvolvido exclusivamente para fins de estudo e aprendizado. N√£o h√° garantia de funcionamento em ambientes de produ√ß√£o ou suporte t√©cnico. Use por sua conta e risco.*

## Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo [LICENSE](./LICENSE.md) para mais detalhes.